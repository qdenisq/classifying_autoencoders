{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# WELCOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import here\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.pytorch_cl_vae.model import ResNet18Classifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# params here\n",
    "params = {\n",
    "    'impath' : \"C:\\Study\\classifying_autoencoders\\data\\input\\img_align_celeba\\img_align_celeba\",\n",
    "    'attpath' : \"C:\\Study\\classifying_autoencoders\\data\\input/list_attr_celeba.txt\",\n",
    "    'attributes': ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young'],\n",
    "    'classes_dim': [2,2,2,2,2],\n",
    "    'learning_rate': 5e-4,\n",
    "    'num_epochs': 10,\n",
    "    'batch_size': 128,\n",
    "    'image_size': 224\n",
    "}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing the CelebA dataset...\n"
     ]
    }
   ],
   "source": [
    "from src.loader import get_loader\n",
    "from src.loader import chew\n",
    "\n",
    "data_loader = get_loader(params['impath'],\n",
    "                  params['attpath'],\n",
    "                  params['attributes'],\n",
    "                  batch_size=params['batch_size'],\n",
    "                  image_size=params['image_size'])\n",
    "# xs, ys = next(iter(dset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Create Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "optimizers = []\n",
    "for idx, (name, classes_dim) in enumerate(zip(params['attributes'], params['classes_dim'])):\n",
    "    classifier = ResNet18Classifier(label_dim=params['classes_dim'][idx]).to(device)\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=params['learning_rate'])\n",
    "    \n",
    "    classifiers.append(classifier)\n",
    "    optimizers.append(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|progress: 200.00% | train step: 100 | losses: {'Black_Hair': 0.4187580347061157, 'Blond_Hair': 0.1921710968017578, 'Brown_Hair': 0.43640783429145813, 'Male': 0.14870679378509521, 'Young': 0.3842095136642456} | accuracies: {'Black_Hair': 0.796875, 'Blond_Hair': 0.921875, 'Brown_Hair': 0.78125, 'Male': 0.984375, 'Young': 0.8125} |8125} |||\n",
      "|progress: 400.00% | train step: 200 | losses: {'Black_Hair': 0.32654911279678345, 'Blond_Hair': 0.15924784541130066, 'Brown_Hair': 0.40704581141471863, 'Male': 0.23876097798347473, 'Young': 0.5028913617134094} | accuracies: {'Black_Hair': 0.875, 'Blond_Hair': 0.921875, 'Brown_Hair': 0.7890625, 'Male': 0.890625, 'Young': 0.8125} |5} |} | ||\n",
      "|progress: 512.00% | train step: 256 | losses: {'Black_Hair': 0.20261931419372559, 'Blond_Hair': 0.16559374332427979, 'Brown_Hair': 0.3389347195625305, 'Male': 0.16671590507030487, 'Young': 0.43385428190231323} | accuracies: {'Black_Hair': 0.921875, 'Blond_Hair': 0.921875, 'Brown_Hair': 0.859375, 'Male': 0.9375, 'Young': 0.796875} |} ||||"
     ]
    }
   ],
   "source": [
    "num_train_samples = len(data_loader)\n",
    "\n",
    "train_step_i = 0\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "for epoch in range(params['num_epochs']):\n",
    "    for x_batch, ws_batch in data_loader:\n",
    "        ws_batch = chew(ws_batch)\n",
    "        train_step_i += 1\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        for label_index, (classifier, optim) in enumerate(zip(classifiers, optimizers)):\n",
    "            x_batch = x_batch.to(device)\n",
    "            optim.zero_grad()\n",
    "#             classifier.train()\n",
    "            predictions, _ = classifier(x_batch)\n",
    "            w_true = ws_batch[label_index].long()\n",
    "#             w_true = w_true.max(1)[1]\n",
    "            labels = w_true.max(1)[1].squeeze().to(device)\n",
    "            loss = CrossEntropyLoss()(predictions, labels)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            losses.append(loss.item())\n",
    "            labels = w_true.max(1)[1].squeeze()\n",
    "            labels_predict = predictions.max(1)[1].squeeze().detach().cpu().numpy()\n",
    "            acc = accuracy_score(labels, labels_predict)\n",
    "            accuracies.append(acc)\n",
    "            \n",
    "        train_losses.append(losses)\n",
    "        train_accuracies.append(accuracies)\n",
    "        loss_dict = dict(zip(params['attributes'], losses))\n",
    "        acc_dict = dict(zip(params['attributes'], accuracies))\n",
    "        print(\"\\r|progress: {:.2f}% | train step: {} | losses: {} | accuracies: {} |\".format(\n",
    "            100.* train_step_i / (num_train_samples // params['batch_size'] * params['num_epochs']), train_step_i,\n",
    "                  loss_dict, acc_dict), end='')\n",
    "        if train_step_i % 100 == 0:\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = np.array(train_losses)\n",
    "train_accuracies = np.array(train_accuracies)\n",
    "\n",
    "for i, attr in enumerate(params['attributes']):\n",
    "    plt.plot(train_losses[:, i])\n",
    "    plt.title(attr)\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(train_accuracies[:, i])\n",
    "    plt.title(attr)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
