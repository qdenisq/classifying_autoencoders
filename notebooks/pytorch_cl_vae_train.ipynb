{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic Classifying VAE for MNIST Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir:  C:\\Study\\classifying_autoencoders\\notebooks\n",
      "Initial path:  ['', 'C:\\\\Study', 'C:\\\\Study\\\\openai\\\\baselines', 'C:\\\\ProgramData\\\\Anaconda3\\\\python36.zip', 'C:\\\\ProgramData\\\\Anaconda3\\\\DLLs', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\ProgramData\\\\Anaconda3', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Babel-2.5.0-py3.6.egg', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\praat_formants_python-0.1.1-py3.6.egg', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\python_praat_scripts-0.2.1-py3.6.egg', 'c:\\\\study\\\\quadrotor_rl\\\\gym-aero', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\s3628075\\\\.ipython']\n",
      "\n",
      "Updated path:  ['', 'C:\\\\Study', 'C:\\\\Study\\\\openai\\\\baselines', 'C:\\\\ProgramData\\\\Anaconda3\\\\python36.zip', 'C:\\\\ProgramData\\\\Anaconda3\\\\DLLs', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\ProgramData\\\\Anaconda3', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Babel-2.5.0-py3.6.egg', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\praat_formants_python-0.1.1-py3.6.egg', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\python_praat_scripts-0.2.1-py3.6.egg', 'c:\\\\study\\\\quadrotor_rl\\\\gym-aero', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\s3628075\\\\.ipython', '../']\n",
      "\n",
      "PyTorch Version  0.4.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import pprint\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import sys\n",
    "print(\"Current working dir: \", os.getcwd())\n",
    "print(\"Initial path: \", sys.path)\n",
    "sys.path.append(\"../\")\n",
    "print()\n",
    "print(\"Updated path: \", sys.path)\n",
    "from src.pytorch_cl_vae.model import ClVaeModel\n",
    "print()\n",
    "print(\"PyTorch Version \", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Specify parameters for to the VAE and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 100,\n",
    "    'num_epochs': 10,\n",
    "    'latent_dim': 2,\n",
    "    'encoder_hidden_size': 512,\n",
    "    'decoder_hidden_size': 512,\n",
    "    'classifier_hidden_size': 512,\n",
    "    'vae_learning_rate': 0.0001,\n",
    "    'classifier_learning_rate': 0.0001,\n",
    "    'log_dir': '../data/logs',\n",
    "    'model_dir': '../data/models',\n",
    "    'data_dir': '../data'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Fetch MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST db has been successfully loaded, stored in the: \"../data/mldata\"\n",
      "| Train subset shape:(63000, 784) | Test subset shape:(7000, 784) |\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home=params['data_dir'])\n",
    "mnist.data = mnist.data / 255\n",
    "num_samples, input_dim = mnist.data.shape\n",
    "num_classes = len(np.unique(mnist.target))\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(mnist.target)\n",
    "params['classes_dim'] = [num_classes]\n",
    "params['original_dim'] = input_dim\n",
    "print('MNIST db has been successfully loaded, stored in the: \"{}\"'.format(params['data_dir'] + '/mldata'))\n",
    "# split data to train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.1, random_state=0)\n",
    "print(\"| Train subset shape:{} | Test subset shape:{} |\".format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Model successfully initialized with params: \n",
      "{   'batch_size': 100,\n",
      "    'classes_dim': [10],\n",
      "    'classifier_hidden_size': 512,\n",
      "    'classifier_learning_rate': 0.0001,\n",
      "    'data_dir': '../data',\n",
      "    'decoder_hidden_size': 512,\n",
      "    'device': 'cuda:0',\n",
      "    'encoder_hidden_size': 512,\n",
      "    'latent_dim': 2,\n",
      "    'log_dir': '../data/logs',\n",
      "    'model_dir': '../data/models',\n",
      "    'num_epochs': 10,\n",
      "    'original_dim': 784,\n",
      "    'vae_learning_rate': 0.0001}\n",
      "\n",
      "\n",
      "Network Architecture:\n",
      "\n",
      "<src.pytorch_cl_vae.model.ClVaeModel object at 0x000000002C3799B0>\n"
     ]
    }
   ],
   "source": [
    "# Initialize ClVaeModel\n",
    "dev = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(dev)\n",
    "params['device'] = dev\n",
    "model = ClVaeModel(**params)\n",
    "print(\"Model successfully initialized with params: \")\n",
    "pprint.PrettyPrinter(indent=4).pprint(params)\n",
    "print()\n",
    "print()\n",
    "print(\"Network Architecture:\")\n",
    "print()\n",
    "print(model)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 out of 10\n",
      "|train step: 100 | rec loss: 0.2066 | z_dkl loss: 0.0053 | class loss: 1.8918 | w_dkl loss: 0.1120 | class_accuracy: 0.8200 |\n",
      "|train step: 200 | rec loss: 0.2024 | z_dkl loss: 0.0077 | class loss: 1.9057 | w_dkl loss: 0.1253 | class_accuracy: 0.7700 |\n",
      "|train step: 300 | rec loss: 0.1952 | z_dkl loss: 0.0230 | class loss: 1.8461 | w_dkl loss: 0.1013 | class_accuracy: 0.8800 |\n",
      "|train step: 400 | rec loss: 0.2039 | z_dkl loss: 0.0203 | class loss: 1.8729 | w_dkl loss: 0.1137 | class_accuracy: 0.8400 |\n",
      "|train step: 500 | rec loss: 0.2025 | z_dkl loss: 0.0128 | class loss: 1.8834 | w_dkl loss: 0.1532 | class_accuracy: 0.8300 |\n",
      "|train step: 600 | rec loss: 0.1916 | z_dkl loss: 0.0134 | class loss: 1.8644 | w_dkl loss: 0.0486 | class_accuracy: 0.8800 |\n",
      "|train step: 630 | rec loss: 0.1927 | z_dkl loss: 0.0248 | class loss: 1.8806 | w_dkl loss: 0.1123 | class_accuracy: 0.8200 |\n",
      "epoch 2 out of 10\n",
      "|train step: 700 | rec loss: 0.1968 | z_dkl loss: 0.0077 | class loss: 1.8927 | w_dkl loss: 0.0602 | class_accuracy: 0.8200 |\n",
      "|train step: 800 | rec loss: 0.1982 | z_dkl loss: 0.0097 | class loss: 1.8965 | w_dkl loss: 0.1155 | class_accuracy: 0.7600 |\n",
      "|train step: 900 | rec loss: 0.1988 | z_dkl loss: 0.0238 | class loss: 1.8556 | w_dkl loss: 0.0939 | class_accuracy: 0.8200 |\n",
      "|train step: 1000 | rec loss: 0.1863 | z_dkl loss: 0.0079 | class loss: 1.8321 | w_dkl loss: 0.2902 | class_accuracy: 0.8600 |\n",
      "|train step: 1100 | rec loss: 0.1992 | z_dkl loss: 0.0044 | class loss: 1.8691 | w_dkl loss: 0.0812 | class_accuracy: 0.8000 |\n",
      "|train step: 1200 | rec loss: 0.2007 | z_dkl loss: 0.0029 | class loss: 1.8436 | w_dkl loss: 0.1654 | class_accuracy: 0.8600 |\n",
      "|train step: 1260 | rec loss: 0.1948 | z_dkl loss: 0.0142 | class loss: 1.8429 | w_dkl loss: 0.0988 | class_accuracy: 0.8400 |\n",
      "epoch 3 out of 10\n",
      "|train step: 1300 | rec loss: 0.2048 | z_dkl loss: 0.0095 | class loss: 1.9217 | w_dkl loss: 0.0880 | class_accuracy: 0.8100 |\n",
      "|train step: 1400 | rec loss: 0.1896 | z_dkl loss: 0.0109 | class loss: 1.8637 | w_dkl loss: 0.0931 | class_accuracy: 0.8100 |\n",
      "|train step: 1500 | rec loss: 0.1992 | z_dkl loss: 0.0026 | class loss: 1.8384 | w_dkl loss: 0.2615 | class_accuracy: 0.8800 |\n",
      "|train step: 1600 | rec loss: 0.1981 | z_dkl loss: 0.0047 | class loss: 1.8684 | w_dkl loss: 0.0738 | class_accuracy: 0.8200 |\n",
      "|train step: 1700 | rec loss: 0.2016 | z_dkl loss: 0.0136 | class loss: 1.9010 | w_dkl loss: 0.1375 | class_accuracy: 0.7700 |\n",
      "|train step: 1800 | rec loss: 0.1916 | z_dkl loss: 0.0063 | class loss: 1.8352 | w_dkl loss: 0.1325 | class_accuracy: 0.8500 |\n",
      "|train step: 1890 | rec loss: 0.1899 | z_dkl loss: 0.0137 | class loss: 1.8511 | w_dkl loss: 0.1406 | class_accuracy: 0.8400 |\n",
      "epoch 4 out of 10\n",
      "|train step: 1900 | rec loss: 0.1944 | z_dkl loss: 0.0170 | class loss: 1.8442 | w_dkl loss: 0.1791 | class_accuracy: 0.8400 |\n",
      "|train step: 2000 | rec loss: 0.1933 | z_dkl loss: 0.0524 | class loss: 1.8827 | w_dkl loss: 0.1270 | class_accuracy: 0.7700 |\n",
      "|train step: 2100 | rec loss: 0.1986 | z_dkl loss: 0.0056 | class loss: 1.8690 | w_dkl loss: 0.1415 | class_accuracy: 0.7600 |\n",
      "|train step: 2200 | rec loss: 0.1935 | z_dkl loss: 0.0026 | class loss: 1.8690 | w_dkl loss: 0.0945 | class_accuracy: 0.8500 |\n",
      "|train step: 2300 | rec loss: 0.1980 | z_dkl loss: 0.0082 | class loss: 1.8809 | w_dkl loss: 0.1011 | class_accuracy: 0.8200 |\n",
      "|train step: 2400 | rec loss: 0.1970 | z_dkl loss: 0.0307 | class loss: 1.8380 | w_dkl loss: 0.1074 | class_accuracy: 0.8200 |\n",
      "|train step: 2500 | rec loss: 0.1916 | z_dkl loss: 0.0087 | class loss: 1.8820 | w_dkl loss: 0.0880 | class_accuracy: 0.8000 |\n",
      "|train step: 2520 | rec loss: 0.1938 | z_dkl loss: 0.0192 | class loss: 1.8260 | w_dkl loss: 0.1172 | class_accuracy: 0.8600 |\n",
      "epoch 5 out of 10\n",
      "|train step: 2600 | rec loss: 0.1938 | z_dkl loss: 0.0203 | class loss: 1.8560 | w_dkl loss: 0.0782 | class_accuracy: 0.8400 |\n",
      "|train step: 2700 | rec loss: 0.1963 | z_dkl loss: 0.0029 | class loss: 1.8522 | w_dkl loss: 0.0728 | class_accuracy: 0.8300 |\n",
      "|train step: 2800 | rec loss: 0.2048 | z_dkl loss: 0.0028 | class loss: 1.8301 | w_dkl loss: 0.1657 | class_accuracy: 0.8900 |\n",
      "|train step: 2900 | rec loss: 0.2048 | z_dkl loss: 0.0040 | class loss: 1.8452 | w_dkl loss: 0.1844 | class_accuracy: 0.8700 |\n",
      "|train step: 3000 | rec loss: 0.1976 | z_dkl loss: 0.0144 | class loss: 1.8773 | w_dkl loss: 0.1189 | class_accuracy: 0.7600 |\n",
      "|train step: 3100 | rec loss: 0.1893 | z_dkl loss: 0.0195 | class loss: 1.8135 | w_dkl loss: 0.0872 | class_accuracy: 0.8700 |\n",
      "|train step: 3150 | rec loss: 0.1884 | z_dkl loss: 0.0173 | class loss: 1.8621 | w_dkl loss: 0.0548 | class_accuracy: 0.8300 |\n",
      "epoch 6 out of 10\n",
      "|train step: 3200 | rec loss: 0.1934 | z_dkl loss: 0.0039 | class loss: 1.8451 | w_dkl loss: 0.0514 | class_accuracy: 0.8700 |\n",
      "|train step: 3300 | rec loss: 0.1923 | z_dkl loss: 0.0042 | class loss: 1.8532 | w_dkl loss: 0.1109 | class_accuracy: 0.8200 |\n",
      "|train step: 3400 | rec loss: 0.1935 | z_dkl loss: 0.0055 | class loss: 1.8630 | w_dkl loss: 0.1091 | class_accuracy: 0.7800 |\n",
      "|train step: 3500 | rec loss: 0.1968 | z_dkl loss: 0.0149 | class loss: 1.8423 | w_dkl loss: 0.1375 | class_accuracy: 0.8000 |\n",
      "|train step: 3600 | rec loss: 0.1746 | z_dkl loss: 0.0070 | class loss: 1.7994 | w_dkl loss: 0.1559 | class_accuracy: 0.8800 |\n",
      "|train step: 3700 | rec loss: 0.1821 | z_dkl loss: 0.0207 | class loss: 1.7924 | w_dkl loss: 0.1918 | class_accuracy: 0.8900 |\n",
      "|train step: 3780 | rec loss: 0.1995 | z_dkl loss: 0.0150 | class loss: 1.8521 | w_dkl loss: 0.2890 | class_accuracy: 0.8500 |\n",
      "epoch 7 out of 10\n",
      "|train step: 3800 | rec loss: 0.1896 | z_dkl loss: 0.0024 | class loss: 1.8480 | w_dkl loss: 0.0688 | class_accuracy: 0.7800 |\n",
      "|train step: 3900 | rec loss: 0.1913 | z_dkl loss: 0.0085 | class loss: 1.8452 | w_dkl loss: 0.1760 | class_accuracy: 0.8200 |\n",
      "|train step: 4000 | rec loss: 0.1950 | z_dkl loss: 0.0136 | class loss: 1.8547 | w_dkl loss: 0.0655 | class_accuracy: 0.8200 |\n",
      "|train step: 4100 | rec loss: 0.1938 | z_dkl loss: 0.0096 | class loss: 1.8202 | w_dkl loss: 0.1025 | class_accuracy: 0.8300 |\n",
      "|train step: 4200 | rec loss: 0.1881 | z_dkl loss: 0.0030 | class loss: 1.8150 | w_dkl loss: 0.1121 | class_accuracy: 0.8600 |\n",
      "|train step: 4300 | rec loss: 0.2033 | z_dkl loss: 0.0292 | class loss: 1.8468 | w_dkl loss: 0.2010 | class_accuracy: 0.8700 |\n",
      "|train step: 4400 | rec loss: 0.1937 | z_dkl loss: 0.0009 | class loss: 1.8326 | w_dkl loss: 0.1072 | class_accuracy: 0.8500 |\n",
      "|train step: 4410 | rec loss: 0.1918 | z_dkl loss: 0.0241 | class loss: 1.8536 | w_dkl loss: 0.0995 | class_accuracy: 0.8200 |\n",
      "epoch 8 out of 10\n",
      "|train step: 4500 | rec loss: 0.1959 | z_dkl loss: 0.0031 | class loss: 1.8562 | w_dkl loss: 0.2045 | class_accuracy: 0.8400 |\n",
      "|train step: 4600 | rec loss: 0.1989 | z_dkl loss: 0.0253 | class loss: 1.8406 | w_dkl loss: 0.1156 | class_accuracy: 0.8100 |\n",
      "|train step: 4700 | rec loss: 0.1861 | z_dkl loss: 0.0042 | class loss: 1.8000 | w_dkl loss: 0.1224 | class_accuracy: 0.8700 |\n",
      "|train step: 4800 | rec loss: 0.1951 | z_dkl loss: 0.0068 | class loss: 1.8186 | w_dkl loss: 0.1817 | class_accuracy: 0.8500 |\n",
      "|train step: 4900 | rec loss: 0.1889 | z_dkl loss: 0.0143 | class loss: 1.7926 | w_dkl loss: 0.1563 | class_accuracy: 0.8700 |\n",
      "|train step: 5000 | rec loss: 0.2028 | z_dkl loss: 0.0415 | class loss: 1.8181 | w_dkl loss: 0.1195 | class_accuracy: 0.8400 |\n",
      "|train step: 5040 | rec loss: 0.1867 | z_dkl loss: 0.0052 | class loss: 1.8201 | w_dkl loss: 0.1149 | class_accuracy: 0.8500 |\n",
      "epoch 9 out of 10\n",
      "|train step: 5100 | rec loss: 0.2012 | z_dkl loss: 0.0023 | class loss: 1.8680 | w_dkl loss: 0.1127 | class_accuracy: 0.8100 |\n",
      "|train step: 5200 | rec loss: 0.1953 | z_dkl loss: 0.0194 | class loss: 1.7806 | w_dkl loss: 0.1842 | class_accuracy: 0.9000 |\n",
      "|train step: 5300 | rec loss: 0.1946 | z_dkl loss: 0.0119 | class loss: 1.8150 | w_dkl loss: 0.1152 | class_accuracy: 0.8500 |\n",
      "|train step: 5400 | rec loss: 0.1958 | z_dkl loss: 0.0034 | class loss: 1.8599 | w_dkl loss: 0.1537 | class_accuracy: 0.8300 |\n",
      "|train step: 5500 | rec loss: 0.1873 | z_dkl loss: 0.0122 | class loss: 1.8059 | w_dkl loss: 0.2130 | class_accuracy: 0.8400 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|train step: 5600 | rec loss: 0.1908 | z_dkl loss: 0.0150 | class loss: 1.8133 | w_dkl loss: 0.0981 | class_accuracy: 0.8900 |\n",
      "|train step: 5670 | rec loss: 0.1810 | z_dkl loss: 0.0057 | class loss: 1.7781 | w_dkl loss: 0.0545 | class_accuracy: 0.9000 |\n",
      "epoch 10 out of 10\n",
      "|train step: 5700 | rec loss: 0.1948 | z_dkl loss: 0.0083 | class loss: 1.8098 | w_dkl loss: 0.0909 | class_accuracy: 0.8400 |\n",
      "|train step: 5800 | rec loss: 0.1947 | z_dkl loss: 0.0266 | class loss: 1.8689 | w_dkl loss: 0.0670 | class_accuracy: 0.7800 |\n",
      "|train step: 5900 | rec loss: 0.1903 | z_dkl loss: 0.0035 | class loss: 1.8108 | w_dkl loss: 0.0951 | class_accuracy: 0.8600 |\n",
      "|train step: 6000 | rec loss: 0.1978 | z_dkl loss: 0.0067 | class loss: 1.8756 | w_dkl loss: 0.1042 | class_accuracy: 0.7800 |\n",
      "|train step: 6100 | rec loss: 0.1909 | z_dkl loss: 0.0186 | class loss: 1.8200 | w_dkl loss: 0.0990 | class_accuracy: 0.8800 |\n",
      "|train step: 6200 | rec loss: 0.2054 | z_dkl loss: 0.0042 | class loss: 1.8199 | w_dkl loss: 0.1084 | class_accuracy: 0.8700 |\n",
      "|train step: 6300 | rec loss: 0.1940 | z_dkl loss: 0.0093 | class loss: 1.8345 | w_dkl loss: 0.2019 | class_accuracy: 0.8200 |\n",
      "*****Finished with the final loss:  Losses(rec_loss=tensor(0.1940, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>), z_dkl_loss=tensor(0.0093, device='cuda:0', grad_fn=<MulBackward>), class_loss_0=tensor(1.8345, device='cuda:0', grad_fn=<NllLossBackward>), w_dkl_loss_0=tensor(0.2019, device='cuda:0', grad_fn=<MulBackward>))\n"
     ]
    }
   ],
   "source": [
    "save_each_steps = 500\n",
    "\n",
    "# Train loop\n",
    "train_step_i = 0\n",
    "for epoch in range(params['num_epochs']):\n",
    "    print('\\nepoch {} out of {}'.format(epoch + 1, params['num_epochs']))\n",
    "    for i in range(X_train.shape[0] // params['batch_size']):\n",
    "        # Sample batch\n",
    "        idx = random.choice(np.arange(0, X_train.shape[0]), params['batch_size'])\n",
    "        x_batch = torch.from_numpy(X_train[idx]).float().to(torch.device(dev))\n",
    "        y_batch = lb.transform(y_train[idx])\n",
    "        y_batch = [torch.from_numpy(y_batch).float().to(torch.device(dev))]\n",
    "        step_losses, step_accuracies = model.train_step(x_batch, y_batch)\n",
    "\n",
    "#         step_losses = [loss.sum().detach().numpy() for loss in step_losses]\n",
    "        # step_losses = Losses(*step_losses)\n",
    "        # step_accuracies = Accuracies(*step_accuracies)\n",
    "\n",
    "        train_losses.append(step_losses)\n",
    "        train_accuracies.append(step_accuracies)\n",
    "\n",
    "        train_step_i += 1\n",
    "\n",
    "        print(\"\\r|train step: {} | rec loss: {:.4f} | z_dkl loss: {:.4f} | class loss: {:.4f}\"\n",
    "              \" | w_dkl loss: {:.4f} | class_accuracy: {:.4f} |\".format(\n",
    "            train_step_i, *step_losses, *step_accuracies\n",
    "            ), end='')\n",
    "        if train_step_i % 100 == 0:\n",
    "            print()\n",
    "        if train_step_i % save_each_steps == 0:\n",
    "            dt = str(datetime.datetime.now().strftime(\"%m_%d_%Y_%I_%M_%p\"))\n",
    "            fname = params['model_dir'] + '/cl_vae_mnist_{}.pt'.format(dt)\n",
    "            model.save_ckpt(fname)\n",
    "model.save_ckpt(params['model_dir'] + '/cl_vae_mnist_last.pt')\n",
    "print('*****Finished with the final loss: ', step_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Show losses graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "losses = defaultdict(list)\n",
    "losses_names = train_losses[0]._fields\n",
    "print(losses_names)\n",
    "step_loss = train_losses[0]\n",
    "print(*step_loss)\n",
    "for i, loss_name in enumerate(losses_names):\n",
    "    losses[loss_name] = [l[i] for l in train_losses]\n",
    "    plt.figure()\n",
    "    plt.title(loss_name)\n",
    "    plt.plot(losses[loss_name])\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
