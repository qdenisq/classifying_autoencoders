{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic Classifying VAE for MNIST Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import pprint\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import datetime\n",
    "from src.pytorch_cl_vae.model import ClVaeModel\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Specify parameters for to the VAE and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 100,\n",
    "    'num_epochs': 50,\n",
    "    'latent_dim': 2,\n",
    "    'encoder_hidden_size': 512,\n",
    "    'decoder_hidden_size': 512,\n",
    "    'classifier_hidden_size': 512,\n",
    "    'vae_learning_rate': 0.0001,\n",
    "    'classifier_learning_rate': 0.0001,\n",
    "    'log_dir': '../data/logs',\n",
    "    'model_dir': '../data/models',\n",
    "    'data_dir': '../data'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Fetch MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST db has been successfully loaded, stored in the: \"../data/mldata\"\n",
      "| Train subset shape:(63000, 784) | Test subset shape:(7000, 784) |\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home=params['data_dir'])\n",
    "mnist.data = mnist.data / 255\n",
    "num_samples, input_dim = mnist.data.shape\n",
    "num_classes = len(np.unique(mnist.target))\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(mnist.target)\n",
    "params['classes_dim'] = [num_classes]\n",
    "params['original_dim'] = input_dim\n",
    "print('MNIST db has been successfully loaded, stored in the: \"{}\"'.format(params['data_dir'] + '/mldata'))\n",
    "# split data to train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.1, random_state=0)\n",
    "print(\"| Train subset shape:{} | Test subset shape:{} |\".format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully initialized with params: \n",
      "{   'batch_size': 100,\n",
      "    'classes_dim': [10],\n",
      "    'classifier_hidden_size': 512,\n",
      "    'classifier_learning_rate': 0.0001,\n",
      "    'data_dir': '../data',\n",
      "    'decoder_hidden_size': 512,\n",
      "    'encoder_hidden_size': 512,\n",
      "    'latent_dim': 2,\n",
      "    'log_dir': '../data/logs',\n",
      "    'model_dir': '../data/models',\n",
      "    'num_epochs': 50,\n",
      "    'original_dim': 784,\n",
      "    'vae_learning_rate': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# Initialize ClVaeModel\n",
    "model = ClVaeModel(**params)\n",
    "print(\"Model successfully initialized with params: \")\n",
    "pprint.PrettyPrinter(indent=4).pprint(params)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 out of 50\n",
      "\r",
      "|train step: 1 | rec loss: 54457.4727 | z_dkl loss: 0.8549 | class loss: 2304.1892 | w_dkl loss: 6.0656 | class_accuracy: 0.1100 |\r",
      "|train step: 2 | rec loss: 54269.2461 | z_dkl loss: 1.1503 | class loss: 2308.1626 | w_dkl loss: 4.7844 | class_accuracy: 0.0900 |\r",
      "|train step: 3 | rec loss: 54094.4023 | z_dkl loss: 1.6776 | class loss: 2315.0479 | w_dkl loss: 4.4916 | class_accuracy: 0.1000 |\r",
      "|train step: 4 | rec loss: 53887.4922 | z_dkl loss: 2.9424 | class loss: 2312.0674 | w_dkl loss: 4.0443 | class_accuracy: 0.0400 |\r",
      "|train step: 5 | rec loss: 53725.0586 | z_dkl loss: 3.8920 | class loss: 2304.4199 | w_dkl loss: 3.5206 | class_accuracy: 0.1000 |\r",
      "|train step: 6 | rec loss: 53584.9766 | z_dkl loss: 6.5561 | class loss: 2314.7642 | w_dkl loss: 3.9260 | class_accuracy: 0.0600 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|train step: 100 | rec loss: 23058.5098 | z_dkl loss: 3321.5752 | class loss: 2228.2136 | w_dkl loss: 33.1309 | class_accuracy: 0.2200 |\n",
      "|train step: 200 | rec loss: 22057.6641 | z_dkl loss: 1979.1127 | class loss: 2201.6150 | w_dkl loss: 64.0202 | class_accuracy: 0.3100 |\n",
      "|train step: 300 | rec loss: 20551.3203 | z_dkl loss: 1529.8494 | class loss: 2170.4097 | w_dkl loss: 111.6069 | class_accuracy: 0.4300 |\n",
      "|train step: 400 | rec loss: 19169.2305 | z_dkl loss: 1454.5453 | class loss: 2154.4675 | w_dkl loss: 137.0563 | class_accuracy: 0.4000 |\n",
      "|train step: 500 | rec loss: 18671.7109 | z_dkl loss: 1189.8763 | class loss: 2072.7827 | w_dkl loss: 185.5578 | class_accuracy: 0.5600 |\n",
      "|train step: 600 | rec loss: 18743.2188 | z_dkl loss: 1073.1919 | class loss: 2070.5984 | w_dkl loss: 213.8250 | class_accuracy: 0.5400 |\n",
      "|train step: 630 | rec loss: 17764.0254 | z_dkl loss: 1005.8671 | class loss: 2041.4550 | w_dkl loss: 230.3179 | class_accuracy: 0.6000 |\n",
      "epoch 2 out of 50\n",
      "|train step: 700 | rec loss: 18330.5957 | z_dkl loss: 1014.8386 | class loss: 2043.4790 | w_dkl loss: 262.6881 | class_accuracy: 0.6700 |\n",
      "|train step: 800 | rec loss: 18318.8398 | z_dkl loss: 846.1362 | class loss: 1981.5483 | w_dkl loss: 310.7372 | class_accuracy: 0.6700 |\n",
      "|train step: 900 | rec loss: 17983.6816 | z_dkl loss: 808.9225 | class loss: 2021.2084 | w_dkl loss: 356.7331 | class_accuracy: 0.5400 |\n",
      "|train step: 1000 | rec loss: 16865.5078 | z_dkl loss: 746.4430 | class loss: 1957.8392 | w_dkl loss: 424.2793 | class_accuracy: 0.6300 |\n",
      "|train step: 1100 | rec loss: 16838.8613 | z_dkl loss: 736.6857 | class loss: 1938.8828 | w_dkl loss: 469.4226 | class_accuracy: 0.6900 |\n",
      "|train step: 1200 | rec loss: 17285.7461 | z_dkl loss: 659.0794 | class loss: 1877.8114 | w_dkl loss: 543.7870 | class_accuracy: 0.7600 |\n",
      "|train step: 1260 | rec loss: 17272.6680 | z_dkl loss: 635.2462 | class loss: 1865.6858 | w_dkl loss: 596.5138 | class_accuracy: 0.7500 |\n",
      "epoch 3 out of 50\n",
      "|train step: 1300 | rec loss: 16691.2305 | z_dkl loss: 612.0333 | class loss: 1951.4332 | w_dkl loss: 589.5488 | class_accuracy: 0.5900 |\n",
      "|train step: 1400 | rec loss: 16488.2070 | z_dkl loss: 582.5687 | class loss: 1927.1836 | w_dkl loss: 603.5851 | class_accuracy: 0.6600 |\n",
      "|train step: 1500 | rec loss: 16488.0645 | z_dkl loss: 567.1417 | class loss: 1911.9211 | w_dkl loss: 638.9808 | class_accuracy: 0.6700 |\n",
      "|train step: 1600 | rec loss: 15702.6191 | z_dkl loss: 565.7648 | class loss: 1867.7174 | w_dkl loss: 653.0929 | class_accuracy: 0.7800 |\n",
      "|train step: 1700 | rec loss: 15067.1953 | z_dkl loss: 529.5616 | class loss: 1863.9813 | w_dkl loss: 685.9086 | class_accuracy: 0.6900 |\n",
      "|train step: 1800 | rec loss: 15251.0625 | z_dkl loss: 511.1531 | class loss: 1903.9147 | w_dkl loss: 675.5267 | class_accuracy: 0.7000 |\n",
      "|train step: 1890 | rec loss: 14999.9072 | z_dkl loss: 519.1381 | class loss: 1895.1687 | w_dkl loss: 656.9618 | class_accuracy: 0.6900 |\n",
      "epoch 4 out of 50\n",
      "|train step: 1900 | rec loss: 15310.7383 | z_dkl loss: 502.0670 | class loss: 1875.1648 | w_dkl loss: 635.8141 | class_accuracy: 0.7500 |\n",
      "|train step: 2000 | rec loss: 14637.1113 | z_dkl loss: 502.0930 | class loss: 1878.8708 | w_dkl loss: 692.6726 | class_accuracy: 0.7100 |\n",
      "|train step: 2100 | rec loss: 15735.3877 | z_dkl loss: 469.1374 | class loss: 1926.7793 | w_dkl loss: 649.8250 | class_accuracy: 0.7300 |\n",
      "|train step: 2200 | rec loss: 15700.7314 | z_dkl loss: 477.7518 | class loss: 1909.4281 | w_dkl loss: 713.7147 | class_accuracy: 0.7000 |\n",
      "|train step: 2300 | rec loss: 13939.6660 | z_dkl loss: 513.9579 | class loss: 1908.5443 | w_dkl loss: 664.3634 | class_accuracy: 0.6800 |\n",
      "|train step: 2400 | rec loss: 14213.8613 | z_dkl loss: 460.6640 | class loss: 1922.1190 | w_dkl loss: 622.1107 | class_accuracy: 0.7200 |\n",
      "|train step: 2500 | rec loss: 14313.2617 | z_dkl loss: 476.6533 | class loss: 1891.6285 | w_dkl loss: 703.1240 | class_accuracy: 0.7200 |\n",
      "|train step: 2520 | rec loss: 14248.5420 | z_dkl loss: 467.2955 | class loss: 1985.9191 | w_dkl loss: 648.8464 | class_accuracy: 0.5700 |\n",
      "epoch 5 out of 50\n",
      "|train step: 2600 | rec loss: 14570.3760 | z_dkl loss: 477.6026 | class loss: 1907.2747 | w_dkl loss: 726.1108 | class_accuracy: 0.6900 |\n",
      "|train step: 2700 | rec loss: 14700.5537 | z_dkl loss: 440.8848 | class loss: 1902.3292 | w_dkl loss: 727.2067 | class_accuracy: 0.7300 |\n",
      "|train step: 2800 | rec loss: 14899.3877 | z_dkl loss: 434.9785 | class loss: 1963.7727 | w_dkl loss: 696.4120 | class_accuracy: 0.6500 |\n",
      "|train step: 2900 | rec loss: 14016.1914 | z_dkl loss: 465.5447 | class loss: 2008.1152 | w_dkl loss: 602.0334 | class_accuracy: 0.6500 |\n",
      "|train step: 3000 | rec loss: 14092.7441 | z_dkl loss: 447.2408 | class loss: 1920.8702 | w_dkl loss: 706.1830 | class_accuracy: 0.6800 |\n",
      "|train step: 3100 | rec loss: 13984.3145 | z_dkl loss: 426.5314 | class loss: 1956.7424 | w_dkl loss: 690.0130 | class_accuracy: 0.6300 |\n",
      "|train step: 3150 | rec loss: 14186.1494 | z_dkl loss: 437.5886 | class loss: 1943.8239 | w_dkl loss: 706.0520 | class_accuracy: 0.7300 |\n",
      "epoch 6 out of 50\n",
      "|train step: 3200 | rec loss: 13178.4922 | z_dkl loss: 452.0567 | class loss: 1934.4208 | w_dkl loss: 735.1043 | class_accuracy: 0.7300 |\n",
      "|train step: 3300 | rec loss: 13567.5439 | z_dkl loss: 456.1769 | class loss: 1917.2699 | w_dkl loss: 726.5923 | class_accuracy: 0.7600 |\n",
      "|train step: 3400 | rec loss: 13332.9961 | z_dkl loss: 449.2403 | class loss: 1948.8193 | w_dkl loss: 684.7414 | class_accuracy: 0.7000 |\n",
      "|train step: 3500 | rec loss: 13751.2861 | z_dkl loss: 440.7352 | class loss: 1930.9678 | w_dkl loss: 731.7438 | class_accuracy: 0.7800 |\n",
      "|train step: 3600 | rec loss: 14166.2686 | z_dkl loss: 433.5568 | class loss: 1940.8811 | w_dkl loss: 748.6820 | class_accuracy: 0.7300 |\n",
      "|train step: 3700 | rec loss: 14107.1621 | z_dkl loss: 405.0656 | class loss: 1992.8876 | w_dkl loss: 730.0158 | class_accuracy: 0.6700 |\n",
      "|train step: 3780 | rec loss: 13971.2832 | z_dkl loss: 439.4135 | class loss: 1997.8022 | w_dkl loss: 689.2068 | class_accuracy: 0.6800 |\n",
      "epoch 7 out of 50\n",
      "|train step: 3800 | rec loss: 13674.1416 | z_dkl loss: 412.1267 | class loss: 1985.2614 | w_dkl loss: 724.9021 | class_accuracy: 0.6800 |\n",
      "|train step: 3900 | rec loss: 13544.3154 | z_dkl loss: 444.8519 | class loss: 1962.7227 | w_dkl loss: 729.9244 | class_accuracy: 0.6800 |\n",
      "|train step: 4000 | rec loss: 12771.0010 | z_dkl loss: 427.6582 | class loss: 1908.3811 | w_dkl loss: 751.1807 | class_accuracy: 0.8000 |\n",
      "|train step: 4100 | rec loss: 13604.4561 | z_dkl loss: 449.2385 | class loss: 1983.5508 | w_dkl loss: 714.2260 | class_accuracy: 0.7200 |\n",
      "|train step: 4200 | rec loss: 13353.0107 | z_dkl loss: 452.0008 | class loss: 1953.2482 | w_dkl loss: 730.4155 | class_accuracy: 0.7500 |\n",
      "|train step: 4300 | rec loss: 13619.0557 | z_dkl loss: 415.8626 | class loss: 1964.7505 | w_dkl loss: 776.2245 | class_accuracy: 0.6600 |\n",
      "|train step: 4400 | rec loss: 13295.3691 | z_dkl loss: 437.8070 | class loss: 1957.0774 | w_dkl loss: 763.6868 | class_accuracy: 0.6900 |\n",
      "|train step: 4410 | rec loss: 13097.8926 | z_dkl loss: 433.5679 | class loss: 1925.8301 | w_dkl loss: 785.4664 | class_accuracy: 0.7900 |\n",
      "epoch 8 out of 50\n",
      "|train step: 4500 | rec loss: 14364.8496 | z_dkl loss: 387.8893 | class loss: 2010.7336 | w_dkl loss: 764.1656 | class_accuracy: 0.6700 |\n",
      "|train step: 4600 | rec loss: 13282.1572 | z_dkl loss: 439.3684 | class loss: 2003.4619 | w_dkl loss: 729.9431 | class_accuracy: 0.6600 |\n",
      "|train step: 4700 | rec loss: 13106.8506 | z_dkl loss: 417.6864 | class loss: 1945.6045 | w_dkl loss: 776.7047 | class_accuracy: 0.7500 |\n",
      "|train step: 4800 | rec loss: 13328.5635 | z_dkl loss: 455.4961 | class loss: 1986.3364 | w_dkl loss: 721.5081 | class_accuracy: 0.7000 |\n",
      "|train step: 4900 | rec loss: 12992.6162 | z_dkl loss: 408.7908 | class loss: 2002.7800 | w_dkl loss: 753.0223 | class_accuracy: 0.6600 |\n",
      "|train step: 5000 | rec loss: 12962.6865 | z_dkl loss: 424.1448 | class loss: 2000.4727 | w_dkl loss: 765.2435 | class_accuracy: 0.7000 |\n",
      "|train step: 5040 | rec loss: 12751.9092 | z_dkl loss: 427.3004 | class loss: 1977.6940 | w_dkl loss: 769.6458 | class_accuracy: 0.7200 |\n",
      "epoch 9 out of 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|train step: 5100 | rec loss: 13257.0986 | z_dkl loss: 431.3175 | class loss: 2039.2487 | w_dkl loss: 759.4855 | class_accuracy: 0.6700 |\n",
      "|train step: 5200 | rec loss: 13080.8379 | z_dkl loss: 444.3137 | class loss: 2002.8621 | w_dkl loss: 779.9443 | class_accuracy: 0.6600 |\n",
      "|train step: 5300 | rec loss: 13357.3916 | z_dkl loss: 415.3503 | class loss: 1978.1544 | w_dkl loss: 816.4803 | class_accuracy: 0.7200 |\n",
      "|train step: 5400 | rec loss: 13612.3711 | z_dkl loss: 415.2617 | class loss: 2016.5980 | w_dkl loss: 811.3365 | class_accuracy: 0.6900 |\n",
      "|train step: 5500 | rec loss: 12916.9844 | z_dkl loss: 436.4155 | class loss: 2029.8784 | w_dkl loss: 772.7612 | class_accuracy: 0.6200 |\n",
      "|train step: 5600 | rec loss: 12700.3701 | z_dkl loss: 437.4919 | class loss: 1977.6785 | w_dkl loss: 790.9957 | class_accuracy: 0.7600 |\n",
      "|train step: 5670 | rec loss: 12934.1699 | z_dkl loss: 411.9921 | class loss: 2025.5322 | w_dkl loss: 797.0225 | class_accuracy: 0.6900 |\n",
      "epoch 10 out of 50\n",
      "|train step: 5700 | rec loss: 13051.3174 | z_dkl loss: 429.4117 | class loss: 2010.0165 | w_dkl loss: 781.5462 | class_accuracy: 0.7300 |\n",
      "|train step: 5800 | rec loss: 13737.2891 | z_dkl loss: 404.2198 | class loss: 2052.2227 | w_dkl loss: 850.9041 | class_accuracy: 0.5700 |\n",
      "|train step: 5900 | rec loss: 12890.3613 | z_dkl loss: 412.1695 | class loss: 1990.0812 | w_dkl loss: 866.3123 | class_accuracy: 0.7100 |\n",
      "|train step: 6000 | rec loss: 13481.7373 | z_dkl loss: 425.0488 | class loss: 2032.1766 | w_dkl loss: 833.2432 | class_accuracy: 0.7000 |\n",
      "|train step: 6100 | rec loss: 12547.4385 | z_dkl loss: 438.3006 | class loss: 1998.1572 | w_dkl loss: 808.8649 | class_accuracy: 0.6800 |\n",
      "|train step: 6200 | rec loss: 12990.2451 | z_dkl loss: 410.6754 | class loss: 2029.1885 | w_dkl loss: 794.0931 | class_accuracy: 0.7000 |\n",
      "|train step: 6300 | rec loss: 13160.3232 | z_dkl loss: 433.0066 | class loss: 2010.0043 | w_dkl loss: 774.8981 | class_accuracy: 0.7600 |\n",
      "\n",
      "epoch 11 out of 50\n",
      "|train step: 6400 | rec loss: 12939.1826 | z_dkl loss: 417.1926 | class loss: 2029.7900 | w_dkl loss: 841.6304 | class_accuracy: 0.6400 |\n",
      "|train step: 6500 | rec loss: 12155.1650 | z_dkl loss: 427.8653 | class loss: 1986.9138 | w_dkl loss: 824.0551 | class_accuracy: 0.7300 |\n",
      "|train step: 6600 | rec loss: 12796.1465 | z_dkl loss: 428.7139 | class loss: 2012.9165 | w_dkl loss: 826.2983 | class_accuracy: 0.7100 |\n",
      "|train step: 6700 | rec loss: 12957.4229 | z_dkl loss: 427.1502 | class loss: 2029.6895 | w_dkl loss: 840.0479 | class_accuracy: 0.6300 |\n",
      "|train step: 6800 | rec loss: 12885.0566 | z_dkl loss: 419.8972 | class loss: 2021.7677 | w_dkl loss: 804.4854 | class_accuracy: 0.6600 |\n",
      "|train step: 6900 | rec loss: 12891.0654 | z_dkl loss: 419.6366 | class loss: 2053.9336 | w_dkl loss: 829.8132 | class_accuracy: 0.6700 |\n",
      "|train step: 6930 | rec loss: 13217.9922 | z_dkl loss: 405.4833 | class loss: 2014.9757 | w_dkl loss: 871.3115 | class_accuracy: 0.6900 |\n",
      "epoch 12 out of 50\n",
      "|train step: 7000 | rec loss: 12298.1270 | z_dkl loss: 424.4257 | class loss: 1999.2234 | w_dkl loss: 817.9235 | class_accuracy: 0.7100 |\n",
      "|train step: 7100 | rec loss: 12337.8994 | z_dkl loss: 426.8556 | class loss: 1975.1271 | w_dkl loss: 857.2055 | class_accuracy: 0.7500 |\n",
      "|train step: 7200 | rec loss: 12708.1533 | z_dkl loss: 433.2551 | class loss: 2037.7208 | w_dkl loss: 829.3573 | class_accuracy: 0.6600 |\n",
      "|train step: 7300 | rec loss: 12974.0342 | z_dkl loss: 427.3600 | class loss: 2061.3086 | w_dkl loss: 868.2320 | class_accuracy: 0.6500 |\n",
      "|train step: 7400 | rec loss: 12885.5479 | z_dkl loss: 426.9309 | class loss: 2030.2375 | w_dkl loss: 883.8646 | class_accuracy: 0.6500 |\n",
      "|train step: 7500 | rec loss: 11808.6172 | z_dkl loss: 426.3139 | class loss: 1968.2191 | w_dkl loss: 868.0309 | class_accuracy: 0.7700 |\n",
      "|train step: 7560 | rec loss: 12441.2930 | z_dkl loss: 420.7142 | class loss: 2029.4077 | w_dkl loss: 864.2586 | class_accuracy: 0.7000 |\n",
      "epoch 13 out of 50\n",
      "|train step: 7600 | rec loss: 12685.6328 | z_dkl loss: 427.3711 | class loss: 2042.8857 | w_dkl loss: 856.0669 | class_accuracy: 0.7200 |\n",
      "|train step: 7700 | rec loss: 12304.3984 | z_dkl loss: 454.0121 | class loss: 2056.1072 | w_dkl loss: 848.5161 | class_accuracy: 0.6400 |\n",
      "|train step: 7800 | rec loss: 12868.5957 | z_dkl loss: 404.9744 | class loss: 2002.8828 | w_dkl loss: 844.5508 | class_accuracy: 0.7300 |\n",
      "|train step: 7900 | rec loss: 12011.6768 | z_dkl loss: 427.7735 | class loss: 2005.5154 | w_dkl loss: 882.5267 | class_accuracy: 0.7500 |\n",
      "|train step: 8000 | rec loss: 12425.0400 | z_dkl loss: 417.3946 | class loss: 2039.7061 | w_dkl loss: 880.1837 | class_accuracy: 0.6500 |\n",
      "|train step: 8100 | rec loss: 12566.0869 | z_dkl loss: 423.2443 | class loss: 2087.7205 | w_dkl loss: 828.0359 | class_accuracy: 0.6100 |\n",
      "|train step: 8190 | rec loss: 12143.4092 | z_dkl loss: 429.5435 | class loss: 2029.6796 | w_dkl loss: 909.9702 | class_accuracy: 0.7200 |\n",
      "epoch 14 out of 50\n",
      "|train step: 8200 | rec loss: 12967.7627 | z_dkl loss: 398.0822 | class loss: 2052.6060 | w_dkl loss: 888.9686 | class_accuracy: 0.6500 |\n",
      "|train step: 8300 | rec loss: 12481.2188 | z_dkl loss: 413.2713 | class loss: 2044.7188 | w_dkl loss: 883.1549 | class_accuracy: 0.7300 |\n",
      "|train step: 8400 | rec loss: 12128.3545 | z_dkl loss: 429.8607 | class loss: 2056.0222 | w_dkl loss: 870.2464 | class_accuracy: 0.6600 |\n",
      "|train step: 8500 | rec loss: 13115.4443 | z_dkl loss: 445.6984 | class loss: 2036.5525 | w_dkl loss: 910.5742 | class_accuracy: 0.7300 |\n",
      "|train step: 8600 | rec loss: 12665.6680 | z_dkl loss: 439.8317 | class loss: 2045.4723 | w_dkl loss: 918.2911 | class_accuracy: 0.7200 |\n",
      "|train step: 8700 | rec loss: 12432.6895 | z_dkl loss: 432.2602 | class loss: 2056.4631 | w_dkl loss: 890.2427 | class_accuracy: 0.6700 |\n",
      "|train step: 8800 | rec loss: 12139.8701 | z_dkl loss: 438.1355 | class loss: 2054.9807 | w_dkl loss: 874.3754 | class_accuracy: 0.6700 |\n",
      "|train step: 8820 | rec loss: 12823.1172 | z_dkl loss: 431.7644 | class loss: 2039.4829 | w_dkl loss: 889.6915 | class_accuracy: 0.7100 |\n",
      "epoch 15 out of 50\n",
      "|train step: 8900 | rec loss: 12047.9824 | z_dkl loss: 437.1967 | class loss: 2044.2534 | w_dkl loss: 896.5248 | class_accuracy: 0.7000 |\n",
      "|train step: 9000 | rec loss: 11942.9707 | z_dkl loss: 436.7946 | class loss: 2035.9258 | w_dkl loss: 886.0156 | class_accuracy: 0.7500 |\n",
      "|train step: 9100 | rec loss: 12101.8555 | z_dkl loss: 446.4173 | class loss: 2019.0918 | w_dkl loss: 875.9820 | class_accuracy: 0.7300 |\n",
      "|train step: 9200 | rec loss: 11872.8721 | z_dkl loss: 441.6656 | class loss: 2027.8180 | w_dkl loss: 882.9822 | class_accuracy: 0.7300 |\n",
      "|train step: 9300 | rec loss: 12045.9277 | z_dkl loss: 452.0885 | class loss: 2051.7622 | w_dkl loss: 892.8683 | class_accuracy: 0.6900 |\n",
      "|train step: 9400 | rec loss: 11958.8848 | z_dkl loss: 427.2351 | class loss: 2016.8210 | w_dkl loss: 889.4867 | class_accuracy: 0.7200 |\n",
      "|train step: 9450 | rec loss: 12016.8506 | z_dkl loss: 458.9492 | class loss: 2048.5215 | w_dkl loss: 891.6736 | class_accuracy: 0.7300 |\n",
      "epoch 16 out of 50\n",
      "|train step: 9500 | rec loss: 12053.3242 | z_dkl loss: 409.0421 | class loss: 2051.6335 | w_dkl loss: 902.5096 | class_accuracy: 0.6900 |\n",
      "|train step: 9600 | rec loss: 12381.8662 | z_dkl loss: 439.1081 | class loss: 2039.9758 | w_dkl loss: 927.6302 | class_accuracy: 0.7300 |\n",
      "|train step: 9700 | rec loss: 11843.3125 | z_dkl loss: 439.3253 | class loss: 2011.8195 | w_dkl loss: 911.2729 | class_accuracy: 0.7100 |\n",
      "|train step: 9800 | rec loss: 12436.3789 | z_dkl loss: 431.3558 | class loss: 2031.9823 | w_dkl loss: 989.9734 | class_accuracy: 0.6900 |\n",
      "|train step: 9900 | rec loss: 12223.8418 | z_dkl loss: 421.6225 | class loss: 2051.6533 | w_dkl loss: 934.3646 | class_accuracy: 0.7200 |\n",
      "|train step: 10000 | rec loss: 12242.5850 | z_dkl loss: 434.1826 | class loss: 2027.8734 | w_dkl loss: 946.8300 | class_accuracy: 0.7200 |\n",
      "|train step: 10080 | rec loss: 12449.2520 | z_dkl loss: 432.1195 | class loss: 2053.3503 | w_dkl loss: 960.9949 | class_accuracy: 0.6800 |\n",
      "epoch 17 out of 50\n",
      "|train step: 10098 | rec loss: 12405.2236 | z_dkl loss: 428.3116 | class loss: 2036.6196 | w_dkl loss: 911.8234 | class_accuracy: 0.7200 ||"
     ]
    }
   ],
   "source": [
    "save_each_steps = 500\n",
    "\n",
    "# Train loop\n",
    "train_step_i = 0\n",
    "for epoch in range(params['num_epochs']):\n",
    "    print('\\nepoch {} out of {}'.format(epoch + 1, params['num_epochs']))\n",
    "    for i in range(X_train.shape[0] // params['batch_size']):\n",
    "        # Sample batch\n",
    "        idx = random.choice(np.arange(0, X_train.shape[0]), params['batch_size'])\n",
    "        x_batch = torch.from_numpy(X_train[idx]).float()\n",
    "        y_batch = lb.transform(y_train[idx])\n",
    "        y_batch = [torch.from_numpy(y_batch).float()]\n",
    "        step_losses, step_accuracies = model.train_step(x_batch, y_batch)\n",
    "\n",
    "#         step_losses = [loss.sum().detach().numpy() for loss in step_losses]\n",
    "        # step_losses = Losses(*step_losses)\n",
    "        # step_accuracies = Accuracies(*step_accuracies)\n",
    "\n",
    "        train_losses.append(step_losses)\n",
    "        train_accuracies.append(step_accuracies)\n",
    "\n",
    "        train_step_i += 1\n",
    "\n",
    "        print(\"\\r|train step: {} | rec loss: {:.4f} | z_dkl loss: {:.4f} | class loss: {:.4f}\"\n",
    "              \" | w_dkl loss: {:.4f} | class_accuracy: {:.4f} |\".format(\n",
    "            train_step_i, *step_losses, *step_accuracies\n",
    "            ), end='')\n",
    "        if train_step_i % 100 == 0:\n",
    "            print()\n",
    "        if train_step_i % save_each_steps == 0:\n",
    "            dt = str(datetime.datetime.now().strftime(\"%m_%d_%Y_%I_%M_%p\"))\n",
    "            fname = params['model_dir'] + '/cl_vae_mnist_{}.pt'.format(dt)\n",
    "            model.save_ckpt(fname)\n",
    "print('*****Finished with the final loss: ', step_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Show losses graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "losses = defaultdict(list)\n",
    "losses_names = train_losses[0]._fields\n",
    "print(losses_names)\n",
    "step_loss = train_losses[0]\n",
    "print(*step_loss)\n",
    "for i, loss_name in enumerate(losses_names):\n",
    "    losses[loss_name] = [l[i] for l in train_losses]\n",
    "    plt.figure()\n",
    "    plt.title(loss_name)\n",
    "    plt.plot(losses[loss_name])\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses(rec_loss=tensor(0.2667), z_dkl_loss=tensor(0.0654), class_loss_0=tensor(2.3070), w_dkl_loss_0=tensor(0.1143))\n"
     ]
    }
   ],
   "source": [
    "y_test = lb.transform(y_test)\n",
    "losses, acc = model.test(torch.from_numpy(X_test).float(), [torch.from_numpy(y_test).float()])\n",
    "pprint.PrettyPrinter(indent=4).pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
